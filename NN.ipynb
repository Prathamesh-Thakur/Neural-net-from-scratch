{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JTw8oxbbqGNp"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F3eVEbnbqqQL"
      },
      "outputs": [],
      "source": [
        "# Sigmoid activation\n",
        "def sigmoid(output):\n",
        "  return 1.0 / (1.0 + np.exp(-output))\n",
        "\n",
        "# Derivative of sigmoid function, used in backpropogation\n",
        "def sigmoid_prime(output):\n",
        "  return sigmoid(output) * (1 - sigmoid(output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-t_AdKY2wFVW"
      },
      "outputs": [],
      "source": [
        "# Class for defining a layer\n",
        "class Layer:\n",
        "  def __init__(self, n):\n",
        "    self.zs = np.zeros((n, 1)) # Weighted sum and bias\n",
        "    self.activations = np.zeros((n, 1)) # Output of neuron after applying activation function\n",
        "    self.n = n # Number of neurons in the current layer\n",
        "\n",
        "  def set_weight_bias_matrix(self, prev_n): # Initialize weight and bias matrices, along with gradients\n",
        "    self.weights = np.random.normal(loc = 0.0, scale = 1.0, size = (self.n, prev_n)) # Weight matrix\n",
        "    self.biases = np.random.normal(loc = 0.0, scale = 1.0, size = (self.n, 1)) # Bias vector\n",
        "    self.weight_gradients = np.zeros((self.n, prev_n)) # Weight gradient matrix\n",
        "    self.bias_gradients = np.zeros((self.n, 1)) # Bias gradient vector\n",
        "\n",
        "  def set_activations(self, input, input_layer = False): # Calculate activations\n",
        "    n1 = len(self.activations)\n",
        "    if not input_layer:\n",
        "      self.zs = self.weights @ input + self.biases # Weighted sum\n",
        "      self.activations = sigmoid(self.zs) # Activation\n",
        "\n",
        "    else:\n",
        "      self.activations = np.array(input).reshape((-1, 1)) # Set neuron activation to input values for input layer\n",
        "\n",
        "  def get_activations(self): # Return activations\n",
        "    return self.activations\n",
        "\n",
        "  def get_z(self): # Return weighted sum\n",
        "    return self.zs\n",
        "\n",
        "  def get_weights(self): # Return weights\n",
        "    return self.weights\n",
        "\n",
        "  def calc_gradients(self, gradient, activations): # Gradient calculation\n",
        "    gradient = np.resize(gradient, self.zs.shape) # Resize gradient matrix for matrix multiplication\n",
        "    self.weight_gradients = gradient * sigmoid_prime(self.zs) * activations.T # Weight gradients\n",
        "    self.bias_gradients = gradient * sigmoid_prime(self.zs) # Bias gradients\n",
        "    return self.bias_gradients\n",
        "\n",
        "  def update_params(self, learning_rate): # Update parameters\n",
        "    self.weights -= learning_rate * self.weight_gradients\n",
        "    self.biases -= learning_rate * self.bias_gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g-vzjY_UFyk7"
      },
      "outputs": [],
      "source": [
        "# Class for defining feed forward network\n",
        "class Network:\n",
        "  def __init__(self):\n",
        "    self.network = [] # Object for holding layers\n",
        "    self.lengths = [] # Object for holding lengths of all layers\n",
        "    self.network_length = 0 # Network length\n",
        "\n",
        "  # Function for adding layers\n",
        "  def add(self, n):\n",
        "    self.lengths.append(n)\n",
        "    layer = Layer(n)\n",
        "    self.network.append(layer)\n",
        "    self.network_length += 1\n",
        "    if self.network_length > 1:\n",
        "      layer.set_weight_bias_matrix(self.lengths[-2]) # For layers after input layer, set weight and bias matrices\n",
        "\n",
        "  # Training function\n",
        "  def train(self, X, y, learning_rate):\n",
        "    input_length = len(X)\n",
        "    no_of_losses = 0\n",
        "\n",
        "    for i in range(input_length):\n",
        "      # Forward pass\n",
        "      entry = X[i] # Input\n",
        "      y_true = y[i] # Expected output\n",
        "      self.network[0].set_activations(entry, input_layer = True) # Input layer\n",
        "      for j in range(1, self.network_length):\n",
        "        self.network[j].set_activations(self.network[j - 1].get_activations()) # Calculate weighted sum using previous layer's activations\n",
        "\n",
        "      output = self.network[-1].get_activations() # Final output\n",
        "\n",
        "      # For classification\n",
        "      if output > 0.5:\n",
        "        y_pred = 1\n",
        "\n",
        "      else:\n",
        "        y_pred = 0\n",
        "\n",
        "      if y_true != y_pred:\n",
        "        no_of_losses += 1\n",
        "\n",
        "      loss = (y_true - output) ** 2 # Loss function MSE\n",
        "\n",
        "      gradient = np.array([-2 * (y_true - output)]) # Gradient of loss\n",
        "\n",
        "      # Backward pass\n",
        "      for j in range(self.network_length - 1, 0, -1):\n",
        "        gradient = self.network[j].calc_gradients(gradient, self.network[j - 1].get_activations()) # Calculate weight and bias gradients\n",
        "        if j > 1:\n",
        "          weights = self.network[j].get_weights()\n",
        "          gradient = weights.T @ gradient # Calculate gradient to be backpropogated\n",
        "\n",
        "      for k in range(self.network_length - 1, 0, -1): # Final forward pass to update all layer parameters\n",
        "        self.network[k].update_params(learning_rate)\n",
        "\n",
        "    print(\"Accuracy: \", ((input_length - no_of_losses) / input_length) * 100) # Final training accuracy\n",
        "\n",
        "  # Testing function\n",
        "  def test(self, X, y):\n",
        "    input_length = len(X)\n",
        "    no_of_losses = 0\n",
        "    for i in range(input_length):\n",
        "      entry = X[i]\n",
        "      y_true = y[i]\n",
        "      self.network[0].set_activations(entry, input_layer = True)\n",
        "      for j in range(1, self.network_length):\n",
        "        self.network[j].set_activations(self.network[j - 1].get_activations())\n",
        "\n",
        "      output = self.network[-1].get_activations()\n",
        "\n",
        "      if output > 0.5:\n",
        "        y_pred = 1\n",
        "\n",
        "      else:\n",
        "        y_pred = 0\n",
        "\n",
        "      if y_true != y_pred:\n",
        "        no_of_losses += 1\n",
        "\n",
        "    print(\"Accuracy: \", ((input_length - no_of_losses) / input_length) * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sample code cell for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWYjFRuapssG"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# df_train = pd.read_csv(\"/content/train_sub.csv\", header = None)\n",
        "# df_test = pd.read_csv(\"/content/test.csv\", header = None)\n",
        "\n",
        "# df_train.drop(0, axis = 1, inplace = True)\n",
        "# df_train.columns = range(df_train.shape[1])\n",
        "# input_length = len(df_train.columns) - 1\n",
        "\n",
        "# model = Network()\n",
        "\n",
        "# model.add(input_length)\n",
        "# model.add(2)\n",
        "# model.add(3)\n",
        "# model.add(2)\n",
        "# model.add(3)\n",
        "# model.add(1)\n",
        "\n",
        "# print(\"Training:\")\n",
        "# for _ in range(10):\n",
        "#   print(\"Iteration \", _+1)\n",
        "#   temp = df_train.sample(frac = 1, ignore_index = True).values\n",
        "\n",
        "#   X_train = temp[:, 1:]\n",
        "#   X_train = X_train / 255\n",
        "#   train_labels = temp[:, 0]\n",
        "\n",
        "# print(\"Test:\")\n",
        "# test_temp = df_test.values\n",
        "\n",
        "# X_test = test_temp[:, 1:]\n",
        "# X_test = X_test / 255\n",
        "# test_labels = test_temp[:, 0]\n",
        "\n",
        "# model.test(X_test, test_labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
